{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP 2 - Deep Learning avec Keras et Manifold Untangling\n",
    "\n",
    "**L’objectif de cette seconde séance de travaux pratiques est de prendre en main la laibrairie `Keras` [https://keras.io/](https://keras.io/) pour utiliser et entraîner des réseaux de neurones profonds.**\n",
    "\n",
    "Avec `Keras`, les réseaux de neurones avec une structure de chaîne (réseaux « feedforward »), s’utilisent de la manière suivante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On créé ainsi un réseau de neurones vide. On peut alors ajouter des couches avec la fonction `add`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 1 : Régression Logistique avec `Keras`\n",
    "\n",
    "Par exemple, l’ajout d’une couche de projection linéaire (couche complètement connectée) de taille 10, suivi de l’ajout d’une couche d’activation de type `softmax`, peuvent s’effectuer de la manière suivante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Activation\n",
    "model.add(Dense(10,  input_dim=784, name='fc1'))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut ensuite visualiser l’architecture du réseau avec la méthode `summary()` du modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question :\n",
    "\n",
    "Quel modèle de prédiction reconnaissez-vous ? Vérifier le nombre de paramètres du réseau à apprendre dans la méthode `summary()`.\n",
    "- Écrire un script `exo1.py` permettant de créer le réseau de neurone ci-dessus.\n",
    "\n",
    "Avec `Keras`, on va compiler le modèle en lui passant un *loss* (ici l’entropie croisée), une méthode d’optimisation (ici une descente de gradient stochastique, *stochastic gradient descent*, `sgd`), et une métrique d’évaluation (ici le taux de bonne prédiction des catégories, `accuracy`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "learning_rate = 0.1\n",
    "sgd = SGD(learning_rate)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=sgd,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, l’apprentissage du modèle sur des données d’apprentissage est mis en place avec la méthode `fit` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "batch_size = 100\n",
    "nb_epoch = 20\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)\n",
    "model.fit(X_train, Y_train,batch_size=batch_size, epochs=nb_epoch,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- batch_size correspond au nombre d’exemples utilisé pour estimer le gradient de la fonction de coût.  \n",
    "- epochs est le nombre d’époques (*i.e.* passages sur l’ensemble des exemples de la base d’apprentissage) lors de la descente de gradient.  \n",
    "\n",
    "\n",
    "**N.B :** on rappelle que comme dans les TME précédents, les labels données par la supervision doivent être au format « one-hot encoding ».\n",
    "\n",
    "On peut ensuite évaluer les performances du modèle dur l’ensemble de test avec la fonction `evaluate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[0], scores[0]*100))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le premier élément de score renvoie la fonction de coût sur la base de test, le second élément renvoie le taux de bonne détection (accuracy).\n",
    "\n",
    "- Implémenter l’apprentissage du modèle sur la base de train de la base MNIST.  \n",
    "- **Évaluer les performances du réseau sur la base de test et les comparer à celles obtenues lors de la séance précédente (ré-implémentation manuelle de l’algorithme de rétro-propagation). Conclure.**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 2 : Perceptron avec Keras\n",
    "\n",
    "On va maintenant enrichir le modèle de régression logistique en insérant une couche de neurones cachés complètement connectée (suivie d’une fonction d’activation non linéaire de type sigmoïde) entre la couche d’entrée et la couche de sortie.\n",
    "On va ainsi obtenir un réseau de neurones à une couche cachée, le Perceptron (cf. TP2).\n",
    "\n",
    "La première couche de ce réseau peut être obtenue de la manière suivante en `Keras` :\n",
    "\n",
    "- Sur un réseau séquentiel vide, on va ajouter la méthode `add` pour insérer une couche cachée (de dimension 100):  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(100,  input_dim=784, name='fc1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- La non-linéarité de type sigmoïde sera obtenue de la manière suivante :  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide-output": false
   },
   "source": [
    "- **Compléter le script pour ajouter la couche de sortie à 10 classes suivie de la fonction d’activation soft-max, comme dans l’exercice 1.** **N.B :** La dimension d’entrée n’a besoin d’être fournie que pour la couche d’entrée.  \n",
    "- Quel est maintenant le nombre de paramètres du modèle MLP ? Justifier le calcul et le vérifier avec la méthode `summary()`.  \n",
    "\n",
    "\n",
    "**Une fois le modèle MLP créé, la façon de l’entraîner est strictement identique à ce qui a été écrit dans l’exercice précédent, l’algorithme de rétro-propagation du gradient de l’erreur permettant de mettre à jour l’ensemble des paramètres du réseau.**\n",
    "\n",
    "- **Compléter le script afin d’effectuer l’entraînement du réseau MLP.**\n",
    "- **Évaluer les performances du réseau sur la base de test et les comparer à celles obtenues lors de la séance précédente. Conclure.**  \n",
    "- Observer la documentation `Keras` pour voir la façon dont les paramètres du modèles sont initialisés dans les différentes couches.  \n",
    "- On pourra utiliser la méthode suivante pour sauvegarder le modèle appris : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_yaml\n",
    "def saveModel(model, savename):\n",
    "  # serialize model to YAML\n",
    "  model_yaml = model.to_yaml()\n",
    "  with open(savename+\".yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "    print(\"Yaml Model \",savename,\".yaml saved to disk\")\n",
    "  # serialize weights to HDF5\n",
    "  model.save_weights(savename+\".h5\")\n",
    "  print(\"Weights \",savename,\".h5 saved to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 3 : Réseaux de neurones convolutifs avec Keras\n",
    "\n",
    "On va maintenant étendre le perceptron de l’exercice précédent pour mettre en place un réseau de neurones convolutif profond, « Convolutionnal Neural Networks », ConvNets.\n",
    "\n",
    "**Écrire un script pour mettre en place un ConvNet.**\n",
    "\n",
    "Les réseaux convolutifs manipulent des images multi-dimensionnelles en entrée (tenseurs). On va donc commencer par reformater les données d’entrée afin que chaque exemple soit de taille $ 28 \\times 28 \\times 1 $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "input_shape = (28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par rapport aux réseaux complètement connectés, les réseaux convolutifs utilisent les briques élémentaires suivantes :\n",
    "\n",
    "1. Des couches de convolution, qui transforment un tenseur d’entrée de taille $ n_x \\times n_y \\times p $ en un tenseur de sortie $ n_{x'} \\times n_{y'} \\times n_H $, où $ n_H $ est le nombre de filtres choisi.\n",
    "Par exemple, une couche de convolution pour traiter les images d’entrée de MNIST peut être créée de la manière suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "conv1 = Conv2D(32,kernel_size=(5, 5),activation='relu',input_shape=(28, 28, 1),padding='valid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 32 est le nombre de filtres.  \n",
    "- (5, 5) est la taille spatiale de chaque filtre (masque de convolution).  \n",
    "- padding=”valid” correspond ignorer les bords lors du calcul (et donc à diminuer la taille spatiale en sortie de la convolution).  \n",
    "- **N.B. :**  on peut directement inclure dans la couche de convolution la non-linéarité en sortie de la convolution, comme illustré ici dans l’exemple avec une fonction d’activation de type `relu`.  \n",
    "\n",
    "\n",
    "1. Des couches d’agrégation spatiale (pooling), afin de permettre une invariance aux translations locales. Voici par exemple la manière de déclarer une couche de max-pooling:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "pool1 = MaxPooling2D(pool_size=(2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (2, 2) est la taille spatiale sur laquelle l’opération d’agrégation est effectuée.  \n",
    "- **N.B. :**  par défaut, le pooling est effectué avec un décalage de 2 neurones, dans l’exemple précédent on obtient donc des cartes de sorties avec des tailles spatiales divisées par deux par rapport à la taille d’entrée.  \n",
    "\n",
    "\n",
    "**Compléter le script pour mettre en place un ConvNet à l’architecture suivante, proche du modèle historique LeNet5** [[LBD+89]](#lecun1989backpropagation) **et montré ci-dessous:**\n",
    "\n",
    "- Une couche de convolution avec 16 filtres de taille $ 5 \\times 5 $, suivie d’une non linéarité de type relu puis d’une couche de max pooling de taille $ 2 \\times 2 $.  \n",
    "- Une seconde couche de convolution avec 32 filtres de taille $ 5 \\times 5 $, suivie d’une non linéarité de type relu puis d’une couche de max pooling de taille $ 2 \\times 2 $.  \n",
    "- Comme dans le réseau LeNet, on considérera la sortie du second bloc convolutif comme un vecteur, ce que revient à « mettre à plat » les couches convolutives précédentes (`model.add(Flatten())`).  \n",
    "- Une couche complètement connectée de taille 100, suivie d’une non linéarité de type sigmoïde.  \n",
    "- Une couche complètement connectée de taille 10, suivie d’une non linéarité de type softmax.  \n",
    "\n",
    "\n",
    "<img src=\"http://cedric.cnam.fr/vertigo/Cours/ml2/_images/LeNet5.png\" style=\"height:200px;\" align=\"center\">\n",
    "\n",
    "- **Apprendre le modèle et évaluer les performances du réseau sur la base de test.  Vous devez obtenir un score de l’ordre de 99% pour ce modèle ConvNet.**  \n",
    "\n",
    "\n",
    "**Apprentissage sur GPU**\n",
    "- Quelle est le temps d’une époque avec ce modèle convolutif ?  \n",
    "- Vous pourrez tester l’apprentissage sur carte graphique du modèle, et comparer le temps d'entraînement\n",
    "\n",
    "\\[LBD+89\\] Yann LeCun, Bernhard Boser, John S Denker, Donnie Henderson, Richard E Howard, Wayne Hubbard, and Lawrence D Jackel. Backpropagation applied to handwritten zip code recognition. *Neural computation*, 1(4):541–551, 1989."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 4 : Visualisation avec t-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On va maintenant illustrer la capacité des réseaux de neurones profonds à apprendre des représentations internes capables de résoudre le problème connu\n",
    "sous le nom de « manifold untangling » en neuroscience, c’est à dire de séparer les exemples des différentes classes dans l’espace de représentations appris.**\n",
    "\n",
    "Pour cela, on va utiliser des outils de visualisation qui vont vont permettre de représenter chaque donnée (par exemple une image de la base MNIST) par un point dans l’espace 2D.\n",
    "Ces même outils vont permettre de projeter en 2D les représentations internes des réseaux de neurones, ce qui va permettre d’analyser la séparabilité des points et des classes\n",
    "dans l’espace d’entrée et dans les espaces de représentions appris par les modèles.\n",
    "\n",
    "**On aura besoin des modules suivants qu’on pourra importer en début de script :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "from scipy.spatial import ConvexHull\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from scipy import linalg\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La méthode *t-Distributed Stochastic Neighbor Embedding* (t-SNE) [[vdMH08]](#tsne08) est une réduction de dimension non linéaire, dont l’objectif est d’assurer que des points proches dans l’espace de départ présentent des positions proches dans l’espace (2D) projeté. Dit autrement, la mesure de distance entre points dans l’espace 2D doit refléter la mesure de distance dans l’espace initial.\n",
    "\n",
    "On va appliquer la méthode t-SNE sur les données brutes **de la base de test de MNIST** en utilisant la classe `TSNE` du module `sklearn.manifold` : [http://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html](http://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html)  .\n",
    "\n",
    "**Créer un script** `exo1.py` **dont l’objectif va être d’effectuer une réduction de dimension en 2D des données de la base de test de MNIST en utilisant la méthode t-SNE.**\n",
    "\n",
    "- Créer une instance de type `TSNE`. **N.B :** on choisira 2 composantes et les paramètres suivants : `init='pca'` (réduire la dimension préalablement avec une ACP), `perplexity=30` (lié au nombre de voisins dans le calcul des distances), `verbose=2` (pour l’affichage lors de l’apprentissage).  \n",
    "- Appliquer la transformation pour obtenir les données projetées en 2D (fonction `fit_transform`). **N.B :** essayer tout d’abord avec un sous-ensemble de la base (*e.g.* 1000 exemples) pour tester l’algorithme, l’apprentissage avec l’ensemble de la base de test pouvant être long.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métrique de séparation des classes\n",
    "\n",
    "On va maintenant compléter le script `exo4.py` précédent afin de visualiser l’ensemble des points projetés en 2D, et de définir\n",
    "des critères pour analyser la séparabilité des classes dans l’espace projeté.\n",
    "\n",
    "1. **Calcul de l’enveloppe convexe des points projetés pour chacune des classe classe.**\n",
    "On utilisera pour cela la la classe `ConvexHull` du module `scipy.spatial` [https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.ConvexHull.html](https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.ConvexHull.html).\n",
    "Sur la base MNIST, on pourra donc utiliser le code suivant pour calculer les enveloppes convexes des points pour les 10 classes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def convexHulls(points, labels):\n",
    "  # computing convex hulls for a set of points with asscoiated labels\n",
    "  convex_hulls = []\n",
    "  for i in range(10):\n",
    "    convex_hulls.append(ConvexHull(points[labels==i,:]))\n",
    "  return convex_hulls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "où `points` (*resp.* `labels`) dans la méthode `convexHulls(points, labels)` correspond aux images projetées dans le plan 2D avec la méthode t-SNE de l’exercice 1 (*resp.* aux labels, *i.e.* classes, des images).\n",
    "\n",
    "2.  **Calcul de l’ellipse de meilleure approximation des points.**\n",
    "On utilisera pour cela la classe `GaussianMixture` du module `sklearn.mixture` [http://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html#sklearn.mixture.GaussianMixture](http://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html#sklearn.mixture.GaussianMixture).\n",
    "On pourra donc utiliser le code suivant pour calculer les ellipses de meilleure approximation pour les 10 classes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def best_ellipses(points, labels):\n",
    "  # computing best fiiting ellipse for a set of points with asscoiated labels\n",
    "  gaussians = []\n",
    "  for i in range(10):\n",
    "    gaussians.append(GaussianMixture(n_components=1, covariance_type='full',init_params='random').fit(points[labels==i, :]))\n",
    "  return gaussians"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Calcul du « Neighborhood Hit » (NH)** [[PNML08]](#dblp-journals-tvcg-paulovichnml08).\n",
    "Pour chaque point, la métrique NH consiste à calculer, pour les k plus proches voisins (`k-nn`) de ce point, le taux des voisins qui sont de la même classe que le point considéré. La métrique NH est ensuite moyennée sur l’ensemble de la base.\n",
    "Le code suivant permet de calculer la métrique NH, en utilisant la classe `NearestNeighbors` du module `sklearn.neighbors` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def neighboring_hit(points, labels):\n",
    "  k = 6\n",
    "  nbrs = NearestNeighbors(n_neighbors=k+1, algorithm='ball_tree').fit(points)\n",
    "  distances, indices = nbrs.kneighbors(points)\n",
    "\n",
    "  txs = 0.0\n",
    "  txsc = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "  nppts = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "\n",
    "  for i in range(len(points)):\n",
    "    tx = 0.0\n",
    "    for j in range(1,k+1):\n",
    "      if (labels[indices[i,j]]== labels[i]):\n",
    "        tx += 1\n",
    "    tx /= k\n",
    "    txsc[labels[i]] += tx\n",
    "    nppts[labels[i]] += 1\n",
    "    txs += tx\n",
    "\n",
    "  for i in range(10):\n",
    "    txsc[i] /= nppts[i]\n",
    "\n",
    "  return txs / len(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question :\n",
    "\n",
    "En quoi les trois métriques ci-dessus sont-elles liées au problème de la séparabilité des classes ? Qu’est-ce qui les diffère ?\n",
    "\n",
    "**Compléter le script** `exo4.py` **pour calculer les différentes métriques.**\n",
    "\n",
    "- Vous pouvez ensuite utiliser la fonction `visualization` suivante pour afficher les points ainsi que leur labels, et de visualiser les trois métriques précédentes :  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing convex hulls, best fitting ellipses & NH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "def visualization(points2D, labels, convex_hulls, ellipses ,projname, nh):\n",
    "    points2D_c= []\n",
    "    for i in range(10):\n",
    "        points2D_c.append(points2D[labels==i, :])\n",
    "    # Data Visualization\n",
    "    cmap =cm.tab10\n",
    "    \n",
    "    plt.figure(figsize=(3.841, 7.195), dpi=100)\n",
    "    plt.set_cmap(cmap)\n",
    "    plt.subplots_adjust(hspace=0.4 )\n",
    "    plt.subplot(311)\n",
    "    plt.scatter(points2D[:,0], points2D[:,1], c=labels,  s=3,edgecolors='none', cmap=cmap, alpha=1.0)\n",
    "    plt.colorbar(ticks=range(10))\n",
    "    plt.title(\"2D \"+projname+\" - NH=\"+str(nh*100.0))\n",
    "    \n",
    "    vals = [ i/10.0 for i in range(10)]\n",
    "    sp2 = plt.subplot(312)\n",
    "    for i in range(10):\n",
    "        ch = np.append(convex_hulls[i].vertices,convex_hulls[i].vertices[0])\n",
    "        sp2.plot(points2D_c[i][ch, 0], points2D_c[i][ch, 1], '-',label='$%i$'%i, color=cmap(vals[i]))\n",
    "  \n",
    "    plt.colorbar(ticks=range(10))\n",
    "    plt.title(projname+\" Convex Hulls\")\n",
    "    \n",
    "    def plot_results(X, Y_, means, covariances, index, title, color):\n",
    "        splot = plt.subplot(3, 1, 3)\n",
    "        for i, (mean, covar) in enumerate(zip(means, covariances)):\n",
    "            v, w = linalg.eigh(covar)\n",
    "            v = 2. * np.sqrt(2.) * np.sqrt(v)\n",
    "            u = w[0] / linalg.norm(w[0])\n",
    "            # as the DP will not use every component it has access to\n",
    "            # unless it needs it, we shouldn't plot the redundant\n",
    "            # components.\n",
    "            if not np.any(Y_ == i):\n",
    "              continue\n",
    "            plt.scatter(X[Y_ == i, 0], X[Y_ == i, 1], .8, color=color, alpha = 0.2)\n",
    "\n",
    "            # Plot an ellipse to show the Gaussian component\n",
    "            angle = np.arctan(u[1] / u[0])\n",
    "            angle = 180. * angle / np.pi  # convert to degrees\n",
    "            ell = mpl.patches.Ellipse(mean, v[0], v[1], 180. + angle, color=color)\n",
    "            ell.set_clip_box(splot.bbox)\n",
    "            ell.set_alpha(0.6)\n",
    "            splot.add_artist(ell)\n",
    "\n",
    "        plt.title(title)\n",
    "    \n",
    "    plt.subplot(313)\n",
    "    for i in range(10):\n",
    "        plot_results(points2D[labels==i, :], ellipses[i].predict(points2D[labels==i, :]), ellipses[i].means_, ellipses[i].covariances_, 0,projname+\" fitting ellipses\", cmap(vals[i]))\n",
    "\n",
    "    plt.savefig(projname+\".png\", dpi=100)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comparer la méthode t-SNE à une Analyse en Composantes Principales (ACP) [[Hot33]](#hotelling1933analysis). On pourra utiliser la classe `PCA` du module `sklearn.decomposition` [http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html). \n",
    "\n",
    "- Analyser la distribution des points et des classes : que peut-on en conclure ?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 5 : Visualisation des représentations internes des réseaux de neurones\n",
    "\n",
    "On va maintenant s’intéresser à visualisation de l’effet de « manifold untangling » permis par les réseaux de neurones.\n",
    "\n",
    "**Créer un script dont l’objectif va être d’utiliser la méthode t-SNE de l’exercice 2 pour projeter les couches cachés des réseaux de neurones dans un espace de dimension 2, ce qui permettra de visualiser la distribution des représentations internes et des labels.**\n",
    "\n",
    "- Commencer par charger le Perceptron entraîné avec `Keras` dans la partie précédente, en utilisant la méthode `loadModel(savename)` suivante:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide-output": false
   },
   "outputs": [],
   "source": [
    "from keras.models import model_from_yaml\n",
    "def loadModel(savename):\n",
    "  with open(savename+\".yaml\", \"r\") as yaml_file:\n",
    "    model = model_from_yaml(yaml_file.read())\n",
    "  print(\"Yaml Model \",savename,\".yaml loaded \")\n",
    "  model.load_weights(savename+\".h5\")\n",
    "  print(\"Weights \",savename,\".h5 loaded \")\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- On pourra vérifier l’architecture du modèle chargé avec la méthode `summary()`.  \n",
    "- On pourra également évaluer les performances du modèle chargé sur la base de test de MNIST pour vérifier son comportement. **N.B :**: il faudra avoir compilé le modèle au préalable.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du modèle \n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On veut maintenant extraire la couche cachée (donc un vecteur de dimension 100) pour chacune des images de la base de test.**\n",
    "\n",
    "- Pour cela, on va utiliser la méthode `model.pop()` (permettant de supprimer la couche au sommet du modèle) deux fois (on supprime la couche d’activation softmax et la couche complètement connectée). Ensuite on peut appliquer la méthode `model.predict(X_test)` sur l’ensemble des données de test.  \n",
    "- Finalement, on va utiliser la méthode t-SNE mise en place à l’exercice 2 pour visualiser les représentations internes des données.  \n",
    "\n",
    "**En plus du Perceptron précédent, on pourra visualiser les représentations internes apprises par un réseau convolutif de type LeNet de la partie précédente.**\n",
    "**Conclure sur la capacité des réseaux de neurones à résoudre le problème du Manifold Untangling.**\n",
    "\n",
    "<a id='hotelling1933analysis'></a>\n",
    "\\[Hot33\\] H. Hotelling. *Analysis of a Complex of Statistical Variables Into Principal Components*. Warwick & York, 1933. URL: [https://books.google.fr/books?id=qJfXAAAAMAAJ](https://books.google.fr/books?id=qJfXAAAAMAAJ).\n",
    "\n",
    "<a id='lecun1989backpropagation'></a>\n",
    "\\[LBD+89\\] Yann LeCun, Bernhard Boser, John S Denker, Donnie Henderson, Richard E Howard, Wayne Hubbard, and Lawrence D Jackel. Backpropagation applied to handwritten zip code recognition. *Neural computation*, 1(4):541–551, 1989.\n",
    "\n",
    "<a id='dblp-journals-tvcg-paulovichnml08'></a>\n",
    "\\[PNML08\\] Fernando Vieira Paulovich, Luis Gustavo Nonato, Rosane Minghim, and Haim Levkowitz. Least square projection: A fast high-precision multidimensional projection technique and its application to document mapping. *IEEE Trans. Vis. Comput. Graph.*, 14(3):564–575, 2008.\n",
    "\n",
    "<a id='tsne08'></a>\n",
    "\\[vdMH08\\] Laurens van der Maaten and Geoffrey E. Hinton. Visualizing high-dimensional data using t-sne. *Journal of Machine Learning Research*, 9:2579–2605, 2008."
   ]
  }
 ],
 "metadata": {
  "date": 1637163670.962602,
  "filename": "tpdisentangling.rst",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "title": "TP 2 - Deep Learning avec Keras et Manifold Untangling"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
